[{"title":"如何解决跨域问题","url":"/2022/09/09/9.9/","content":"<h1 id=\"如何解决跨域问题\"><a href=\"#如何解决跨域问题\" class=\"headerlink\" title=\"如何解决跨域问题\"></a>如何解决跨域问题</h1><span id=\"more\"></span>\n\n<p>我目前发现的比较简单的方法是在后端配置类中写一个Cors Config类</p>\n<pre><code>@Configuration\npublic class CorsConfig &#123;\n\n    // 当前跨域请求最大有效时长。这里默认1天\n    private static final long MAX_AGE = 24 * 60 * 60;\n\n    @Bean\n    public CorsFilter corsFilter() &#123;\n        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();\n        CorsConfiguration corsConfiguration = new CorsConfiguration();\n        corsConfiguration.addAllowedOrigin(&quot;http://localhost:8080&quot;);// 1 设置访问源地址\n        corsConfiguration.addAllowedOrigin(&quot;http://localhost:8081&quot;);//(第二个地址)\n        corsConfiguration.addAllowedHeader(&quot;*&quot;); // 2 设置访问源请求头\n        corsConfiguration.addAllowedMethod(&quot;*&quot;); // 3 设置访问源请求方法\n        corsConfiguration.setMaxAge(MAX_AGE);\n        source.registerCorsConfiguration(&quot;/**&quot;, corsConfiguration); // 4 对接口配置跨域设置\n        return new CorsFilter(source);\n    &#125;\n&#125;\n</code></pre>\n<p>改成你的端口就可以解决跨域问题</p>\n","categories":["后端"],"tags":["跨域"]},{"title":"Anaconda常见命令合集","url":"/2022/10/01/Anaconda%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E5%90%88%E9%9B%86/","content":"<h1 id=\"Anaconda常见命令合集\"><a href=\"#Anaconda常见命令合集\" class=\"headerlink\" title=\"Anaconda常见命令合集\"></a>Anaconda常见命令合集</h1><p>简单记录经常使用的命令</p>\n<span id=\"more\"></span>\n<h3 id=\"1）查看安装了哪些包\"><a href=\"#1）查看安装了哪些包\" class=\"headerlink\" title=\"1）查看安装了哪些包\"></a>1）查看安装了哪些包</h3><pre><code class=\"text\">conda list\n</code></pre>\n<h3 id=\"2-查看当前存在哪些虚拟环境\"><a href=\"#2-查看当前存在哪些虚拟环境\" class=\"headerlink\" title=\"2)查看当前存在哪些虚拟环境\"></a>2)查看当前存在哪些虚拟环境</h3><pre><code class=\"text\">conda env list \nconda info -e\n</code></pre>\n<h3 id=\"3-检查更新当前conda\"><a href=\"#3-检查更新当前conda\" class=\"headerlink\" title=\"3)检查更新当前conda\"></a>3)检查更新当前conda</h3><pre><code class=\"text\">conda update conda\n</code></pre>\n<h3 id=\"3-Python创建虚拟环境\"><a href=\"#3-Python创建虚拟环境\" class=\"headerlink\" title=\"3.Python创建虚拟环境\"></a>3.Python创建虚拟环境</h3><pre><code class=\"text\">conda create -n your_env_name python=x.x\n</code></pre>\n<p>anaconda命令创建python版本为x.x，名字为your_env_name的虚拟环境。<strong>your_env_name文件可以在Anaconda安装目录envs文件下找到</strong>。</p>\n<h3 id=\"4-激活或者切换虚拟环境\"><a href=\"#4-激活或者切换虚拟环境\" class=\"headerlink\" title=\"4.激活或者切换虚拟环境\"></a>4.激活或者切换虚拟环境</h3><p>打开命令行，输入python –version检查当前 python 版本。</p>\n<pre><code class=\"text\">Linux:  source activate your_env_nam\nWindows: activate your_env_name\n</code></pre>\n<h3 id=\"5-对虚拟环境中安装额外的包\"><a href=\"#5-对虚拟环境中安装额外的包\" class=\"headerlink\" title=\"5.对虚拟环境中安装额外的包\"></a>5.对虚拟环境中安装额外的包</h3><pre><code class=\"text\">conda install -n your_env_name [package]\n</code></pre>\n<h3 id=\"6-关闭虚拟环境-即从当前环境退出返回使用PATH环境中的默认python版本\"><a href=\"#6-关闭虚拟环境-即从当前环境退出返回使用PATH环境中的默认python版本\" class=\"headerlink\" title=\"6.关闭虚拟环境(即从当前环境退出返回使用PATH环境中的默认python版本)\"></a>6.关闭虚拟环境(即从当前环境退出返回使用PATH环境中的默认python版本)</h3><pre><code class=\"text\">deactivate env_name\n或者`activate root`切回root环境\nLinux下：source deactivate \n</code></pre>\n<h3 id=\"7-删除虚拟环境\"><a href=\"#7-删除虚拟环境\" class=\"headerlink\" title=\"7.删除虚拟环境\"></a>7.删除虚拟环境</h3><pre><code class=\"text\">conda remove -n your_env_name --all\n</code></pre>\n<h3 id=\"8-删除环境钟的某个包\"><a href=\"#8-删除环境钟的某个包\" class=\"headerlink\" title=\"8.删除环境钟的某个包\"></a>8.删除环境钟的某个包</h3><pre><code class=\"text\">conda remove --name $your_env_name  $package_name \n</code></pre>\n<h3 id=\"9、设置国内镜像\"><a href=\"#9、设置国内镜像\" class=\"headerlink\" title=\"9、设置国内镜像\"></a>9、设置国内镜像</h3><p><a href=\"https://link.zhihu.com/?target=http://Anaconda.org\">http://Anaconda.org</a>的服务器在国外，安装多个packages时，conda下载的速度经常很慢。清华TUNA镜像源有Anaconda仓库的镜像，将其加入conda的配置即可：</p>\n<p># 添加Anaconda的TUNA镜像</p>\n<p>conda config –add channels <a href=\"https://link.zhihu.com/?target=https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a></p>\n<p># TUNA的help中镜像地址加有引号，需要去掉</p>\n<p># 设置搜索时显示通道地址</p>\n","categories":["deep learning"],"tags":["Anaconda"]},{"title":"JAVA解决端口被占用方法","url":"/2022/09/01/date9.1/","content":"<h1 id=\"JAVA解决端口被占用方法\"><a href=\"#JAVA解决端口被占用方法\" class=\"headerlink\" title=\"JAVA解决端口被占用方法\"></a>JAVA解决端口被占用方法</h1><p>在跑项目时发现明明做的一样但报错，搞了半天才发现是80端口被占用了，很生气</p>\n<span id=\"more\"></span>\n\n<p>简单学习了一下如何解决</p>\n<hr>\n<p>第一步：win + R 输入cmd 打开运行窗口<br>第二步：查看占用端口号的进程号（xxx为端口号）</p>\n<pre><code>netstat -nao|findstr xxx\n</code></pre>\n<p>第三步：杀死该进程（xxx为上一步查出来的进程号）</p>\n<pre><code>taskkill /pid xxx -f\n</code></pre>\n<p>有时候用idea开发时遇到项目没有关闭，软件意外关停的问题，导致重新启动项目时出现端口号被占用的情况，用本方法可以很好的解决这个问题。</p>\n<hr>\n<p>最后推荐一下无意之中发现还挺好听的小调：</p>\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"//music.163.com/outchain/player?type=2&id=4233698&auto=1&height=66\"></iframe>\n","categories":["后端"],"tags":["java"]},{"title":"axios问题","url":"/2022/06/23/date9.8/","content":"<h2 id=\"在用axios时页面报错axios-Unsupported-protocol-Http\"><a href=\"#在用axios时页面报错axios-Unsupported-protocol-Http\" class=\"headerlink\" title=\"在用axios时页面报错axios Unsupported protocol Http:\"></a>在用axios时页面报错axios Unsupported protocol Http:</h2><span id=\"more\"></span>\n<p>原因是在0.27.2的版本下不识别url下的：</p>\n<p>所以我目前了解到的办法就是降级</p>\n<pre><code class=\"undefined\">npm install axios@0.26.1\n</code></pre>\n<p>之后一下成功</p>\n","categories":["后端"],"tags":["后端"]},{"title":"一个小失误","url":"/2022/01/23/deploy/","content":"<h1 id=\"一个小失误\"><a href=\"#一个小失误\" class=\"headerlink\" title=\"一个小失误\"></a>一个小失误</h1><p>一个小小的失误，造成了我的hexo的上传一直失败（我的内心是崩溃的），我在谷歌上到处搜解决办法，发现中文的回答几乎都一个样（这里要批评一下），最后还是在撇脚的英文翻译下终于解决了。</p>\n<span id=\"more\"></span>\n\n<p><strong>今日份的分享：</strong></p>\n<p><img src=\"https://s3.bmp.ovh/imgs/2022/07/20/6973ffe95ac81fca.jpg\"></p>\n","categories":["杂谈"],"tags":["hexo"]},{"title":"个人尝试","url":"/2022/01/23/try/","content":"<h1 id=\"个人尝试\"><a href=\"#个人尝试\" class=\"headerlink\" title=\"个人尝试\"></a>个人尝试</h1><span id=\"more\"></span>\n<h2 id=\"为什么写博客\"><a href=\"#为什么写博客\" class=\"headerlink\" title=\"为什么写博客\"></a>为什么写博客</h2><p>一直很纠结要不要写博客，但是思来想去，决定开始制作并更新一个博客，就当给自己的生活增加一点内容吧。</p>\n<h2 id=\"博客的内容\"><a href=\"#博客的内容\" class=\"headerlink\" title=\"博客的内容\"></a>博客的内容</h2><p>目前还没有想好，可能是生活趣事？或者是像其他个人播客一样去教一些教程（本人太菜了可能教不了啥）？总之，先建立一个个人主页，剩下的之后再说吧。</p>\n<h2 id=\"tips\"><a href=\"#tips\" class=\"headerlink\" title=\"tips\"></a>tips</h2><p>我目前比较想在每篇文章后加一个个人的摄影分享，展示一下最近的摄影成功。</p>\n<p><strong>这次的摄影分享就是：</strong></p>\n<p><img src=\"https://s3.bmp.ovh/imgs/2022/07/20/e42d21b4ffe366ff.jpg\"></p>\n","categories":["杂谈"],"tags":["杂谈"]},{"title":"交叉熵 Cross Entropy简单理解","url":"/2022/10/11/%E4%BA%A4%E5%8F%89%E7%86%B5%20Cross%20Entropy/","content":"<h1 id=\"交叉熵-Cross-Entropy\"><a href=\"#交叉熵-Cross-Entropy\" class=\"headerlink\" title=\"交叉熵 Cross Entropy\"></a>交叉熵 Cross Entropy</h1><p>在图像分类任务中，常使用交叉熵损失函数来评估模型的表现</p>\n<span id=\"more\"></span>\n\n<hr>\n<h2 id=\"1-分类错误率\"><a href=\"#1-分类错误率\" class=\"headerlink\" title=\"1.分类错误率\"></a>1.分类错误率</h2><p> 就是直接计算判断失败的概率，然后对比，这种计算方法有很大的问题，他无法展现判断成功的那个是精准预测还是以非常微弱的优势判断正确，这对改进模型有较大的阻碍。</p>\n<h2 id=\"2-均方误差\"><a href=\"#2-均方误差\" class=\"headerlink\" title=\"2.均方误差\"></a>2.均方误差</h2><img src=\"https://tva1.sinaimg.cn/large/008vxvgGly1h809gwxnvlj312g052q3f.jpg\" alt=\" image-20221110193454569\" style=\"zoom:50%;\" />\n\n<p>不难看出，MSE能够判断出来是否准确预测的状况，那为什么不采样这种损失函数呢？主要原因是在分类问题中，使用sigmoid&#x2F;softmx得到概率，配合MSE损失函数时，采用梯度下降法进行学习时，会出现模型一开始训练时，学习速率非常慢的情况</p>\n<h2 id=\"3-交叉熵损失函数\"><a href=\"#3-交叉熵损失函数\" class=\"headerlink\" title=\"3.交叉熵损失函数\"></a>3.交叉熵损失函数</h2><h3 id=\"1-二分\"><a href=\"#1-二分\" class=\"headerlink\" title=\"(1)二分\"></a>(1)二分</h3><p>在二分的情况下，模型最后需要预测的结果只有两种情况，对于每个类别我们的预测得到的概率为 p 和 1−p ，此时表达式为（log 的底数是 e）：</p>\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGly1h809yhb0d4j30wo05yglx.jpg\" alt=\"image-20221110195149583 \" style=\"zoom:33%;\" />\n\n<p>- yi —— 表示样本 i 的label，正类为 1 ，负类为 0<br>- pi —— 表示样本 i 预测为正类的概率</p>\n<h3 id=\"2-多分\"><a href=\"#2-多分\" class=\"headerlink\" title=\"(2)多分\"></a>(2)多分</h3><p>多分类的情况实际上就是对二分类的扩展，公式如下：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGly1h80a7l4jlrj31020duabb.jpg\" alt=\"image-20221110200034924\"></p>\n<p>若预测值为下图</p>\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGly1h80a94ug8lj314c08w0tg.jpg\" alt=\"image-20221110200203807 \" style=\"zoom:33%;\" />\n\n<p>则可得到</p>\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h80ho0aj2wj312k0dqwg1.jpg\" alt=\"image-20221111001829637 \" style=\"zoom:50%;\" />\n\n<p>这种可以很清晰明了的表示该模型的预测水平</p>\n","categories":["deep learning"],"tags":["损失函数"]},{"title":"如何安装Pytorch","url":"/2022/10/02/%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85Pytorch/","content":"<h1 id=\"如何安装Pytorch\"><a href=\"#如何安装Pytorch\" class=\"headerlink\" title=\"如何安装Pytorch\"></a>如何安装Pytorch</h1><span id=\"more\"></span>\n<h2 id=\"一-检测自己以前是否安装过Pytorch\"><a href=\"#一-检测自己以前是否安装过Pytorch\" class=\"headerlink\" title=\"一.检测自己以前是否安装过Pytorch\"></a>一.检测自己以前是否安装过Pytorch</h2><p>打开终端，切换到<a href=\"https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020\">pytorch</a>安装环境下，检测程序如下：</p>\n<pre><code class=\"python\">import torch\nprint（torch.__version__）\nprint(torch.cuda.is_available())\n</code></pre>\n<p>若显示版本号及True则为已安装</p>\n<h2 id=\"二-安装Pytorch\"><a href=\"#二-安装Pytorch\" class=\"headerlink\" title=\"二.安装Pytorch\"></a>二.安装Pytorch</h2><p>首先先安装cuda和cudnn加速包,cudnn下载需要注册账号有点麻烦，这两个的坑比较少</p>\n<p>再创建一个虚拟环境</p>\n<pre><code>conda create -n your_env_name python=x.x\n</code></pre>\n<p>进入虚拟环境</p>\n<pre><code>activate your_env_name\n</code></pre>\n<p>尝试从官网获取安装指令<a href=\"https://pytorch.org,如果安装很慢,就用清华源的镜像pip安装/\">https://pytorch.org，如果安装很慢，就用清华源的镜像pip安装</a></p>\n<pre><code>pip install torch===1.3.0 torchvision===0.4.1 -i https://pypi.tuna.tsinghua.edu.cn/simple\n</code></pre>\n<h2 id=\"三-问题解决\"><a href=\"#三-问题解决\" class=\"headerlink\" title=\"三.问题解决\"></a>三.问题解决</h2><p>如果用上面的命令安装成功了，那还好，若不成功，则多半是网络问题</p>\n<p>注意在下载时不要挂vpn，否则速度也会很慢</p>\n","categories":["deep learning"],"tags":["Pytorch"]},{"title":"线性代数(深度学习版)","url":"/2022/10/05/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0(%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%89%88)/","content":"<h1 id=\"线性代数-深度学习版\"><a href=\"#线性代数-深度学习版\" class=\"headerlink\" title=\"线性代数(深度学习版)\"></a>线性代数(深度学习版)</h1><p>听李沐老师讲课做的笔记</p>\n<span id=\"more\"></span>\n<h2 id=\"标量\"><a href=\"#标量\" class=\"headerlink\" title=\"标量\"></a>标量</h2><p>标量由只有一个元素的张量表示。</p>\n<p>就像</p>\n<pre><code>[3]\n</code></pre>\n<p>可以用一下方法生成出标量并运算</p>\n<pre><code class=\"python\">import torch\n\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\n\nx + y, x * y, x / y, x**y\n</code></pre>\n<h2 id=\"向量\"><a href=\"#向量\" class=\"headerlink\" title=\"向量\"></a>向量</h2><p>你可以将向量视为标量值组成的列表。 我们将这些标量值称为向量的<em>元素</em>（element）或<em>分量</em>（component）。我们通过一维张量处理向量。一般来说，张量可以具有任意长度，取决于机器的内存限制。</p>\n<p>就像</p>\n<pre><code>[0,1,2,3,4,5]\n</code></pre>\n<p>在pytorch中直接可以生成</p>\n<pre><code class=\"python\">x = torch.arange(4)\nx\n</code></pre>\n<h2 id=\"矩阵\"><a href=\"#矩阵\" class=\"headerlink\" title=\"矩阵\"></a>矩阵</h2><p>正如向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。 矩阵，我们通常用粗体、大写字母来表示,如下图示</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h774v9swt7j31400cojst.jpg\" alt=\"image-20221016145421655\"></p>\n<h2 id=\"张量算法\"><a href=\"#张量算法\" class=\"headerlink\" title=\"张量算法\"></a>张量算法</h2><h3 id=\"张量乘标量\"><a href=\"#张量乘标量\" class=\"headerlink\" title=\"张量乘标量\"></a>张量乘标量</h3><p>将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p>\n<h3 id=\"内积\"><a href=\"#内积\" class=\"headerlink\" title=\"内积\"></a>内积</h3><p>两个矩阵A、B对应分量乘积之和，结果为一个标量，记作&lt;A,B&gt;（与向量的内积&#x2F;点积&#x2F;数量积的定义相似）。所以A、B的行数列数都应相同，且有结论&lt;A,B&gt;&#x3D;tr(<em>A^T</em>* B)。与哈达吗积点区别就是，一个乘完是标量，一个乘完是矩阵</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7qu9ga7tkj30sm05saaa.jpg\" alt=\"image-20221102155839244\"></p>\n<h3 id=\"矩阵乘矩阵（哈达玛积）\"><a href=\"#矩阵乘矩阵（哈达玛积）\" class=\"headerlink\" title=\"矩阵乘矩阵（哈达玛积）\"></a>矩阵乘矩阵（哈达玛积）</h3><p>就是按照位对位的乘</p>\n<h3 id=\"矩阵乘矩阵（另一种）\"><a href=\"#矩阵乘矩阵（另一种）\" class=\"headerlink\" title=\"矩阵乘矩阵（另一种）\"></a>矩阵乘矩阵（另一种）</h3><p>简单理解就是把A从竖着变成横着和B对位相乘</p>\n<h3 id=\"矩阵向量积\"><a href=\"#矩阵向量积\" class=\"headerlink\" title=\"矩阵向量积\"></a>矩阵向量积</h3><p>在代码中使用张量表示矩阵-向量积，我们使用与点积相同的<code>mv</code>函数。 当我们为矩阵<code>A</code>和向量<code>x</code>调用<code>torch.mv(A, x)</code>时，会执行矩阵-向量积。 注意，<code>A</code>的列维数（沿轴1的长度）必须与<code>x</code>的维数（其长度）相同。</p>\n<p>复杂理解就是</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h777x7vhiej311w0u0whp.jpg\" alt=\"image-20221016164000897\"></p>\n<h2 id=\"降维\"><a href=\"#降维\" class=\"headerlink\" title=\"降维\"></a>降维</h2><p>通过sum来实现降维，实例如下</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7766fx2kxj314q0aa74y.jpg\" alt=\"image-20221016153941595\"></p>\n<p>当然也可以规定降哪个维</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7767wydbej314q0bc0tq.jpg\" alt=\"image-20221016154106485\"></p>\n<p>通过axis或者dim参数就可以调整，当调整时就遵循（层，行，列）的顺序进行更改,也就是说，降哪个维就是把哪个维归一</p>\n<h2 id=\"非降维\"><a href=\"#非降维\" class=\"headerlink\" title=\"非降维\"></a>非降维</h2><p>可以使用keepdims&#x3D;True这个参数让张量在运算后的轴数不变</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7773u8rtfj314o0fswfh.jpg\" alt=\"image-20221016161147504\"></p>\n<h2 id=\"点积\"><a href=\"#点积\" class=\"headerlink\" title=\"点积\"></a>点积</h2><p>相同位置的张量相乘并相加，命令如下</p>\n<pre><code class=\"python\">y = torch.ones(4, dtype = torch.float32)\nx, y, torch.dot(x, y)\n</code></pre>\n<h2 id=\"广播\"><a href=\"#广播\" class=\"headerlink\" title=\"广播\"></a>广播</h2><h3 id=\"条件\"><a href=\"#条件\" class=\"headerlink\" title=\"条件\"></a>条件</h3><p>当一对张量满足下面的条件时，它们才是可以被“广播”的。</p>\n<p>1、每个张量至少有一个<a href=\"https://so.csdn.net/so/search?q=%E7%BB%B4%E5%BA%A6&spm=1001.2101.3001.7020\">维度</a>。</p>\n<p>2、迭代维度尺寸时，从<strong>尾部</strong>（也就是从后往前）开始，依次每个维度的尺寸必须满足以下之一：</p>\n<ul>\n<li><p><strong>相等</strong>。</p>\n</li>\n<li><p>其中一个张量的维度<strong>尺寸为1</strong>。</p>\n</li>\n<li><p>其中一个张量<strong>不存在</strong>这个维度。</p>\n<pre><code class=\"python\">import torch\n\n# 示例1：相同形状的张量总是可广播的，因为总能满足以上规则。\nx = torch.empty(5, 7, 3)\ny = torch.empty(5, 7, 3)\n\n\n# 示例2：不可广播（ a 不满足第一条规则）。\na = torch.empty((0,))\nb = torch.empty(2, 2)\n\n\n# 示例3：m 和 n 可广播：\nm = torch.empty(5, 3, 4, 1)\nn = torch.empty(   3, 1, 1)\n# 倒数第一个维度：两者的尺寸均为1\n# 倒数第二个维度：n尺寸为1\n# 倒数第三个维度：两者尺寸相同\n# 倒数第四个维度：n该维度不存在\n\n\n# 示例4：不可广播，因为倒数第三个维度：2 != 3\np = torch.empty(5, 2, 4, 1)\nq = torch.empty(   3, 1, 1)\n</code></pre>\n</li>\n</ul>\n<h3 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h3><p>如果张量x和张量y是可广播的，那么广播后的张量尺寸按照如下方法计算：<strong>如果x和y的维数不等，在维数较少的张量上添加尺寸为 1 的维度。结果维度尺寸是x和y相应维度尺寸的较大者。</strong></p>\n<pre><code class=\"python\"># 示例5：可广播\nc = torch.empty(5, 1, 4, 1)\nd = torch.empty(   3, 1, 1)\n(c + d).size()  # torch.Size([5, 3, 4, 1])\n\n\n# 示例6：可广播\nf = torch.empty(      1)\ng = torch.empty(3, 1, 7)\n(f + g).size()  # torch.Size([3, 1, 7])\n\n\n# 示例7：不可广播\no = torch.empty(5, 2, 4, 1)\nu = torch.empty(   3, 1, 1)\n(o + u).size()\n\n# 报错：\n# ---------------------------------------------------------------------------\n#\n# RuntimeError                              Traceback (most recent call last)\n#\n# &lt;ipython-input-17-72fb34250db7&gt; in &lt;module&gt;()\n#       1 o=torch.empty(5,2,4,1)\n#       2 u=torch.empty(3,1,1)\n# ----&gt; 3 (o+u).size()\n#\n# RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n</code></pre>\n<h2 id=\"范数-norm\"><a href=\"#范数-norm\" class=\"headerlink\" title=\"范数(norm)\"></a>范数(norm)</h2><p>非正式地说，一个向量的<em>范数</em>告诉我们一个向量有多大。 这里考虑的<em>大小</em>（size）概念不涉及维度，而是分量的大小。</p>\n<h3 id=\"L2范数\"><a href=\"#L2范数\" class=\"headerlink\" title=\"L2范数\"></a>L2范数</h3><p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h784elm4d1j31480bsq4x.jpg\" alt=\"image-20221017112351840\"></p>\n<h3 id=\"L1范数\"><a href=\"#L1范数\" class=\"headerlink\" title=\"L1范数\"></a>L1范数</h3><p>绝对值之和</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h784fidu9kj315u08wt9b.jpg\" alt=\"image-20221017112447380\"></p>\n<h3 id=\"F范数\"><a href=\"#F范数\" class=\"headerlink\" title=\"F范数\"></a>F范数</h3><p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h784g225mlj315g0dymyz.jpg\" alt=\"image-20221017112518508\"></p>\n","categories":["deep learning"],"tags":["线性代数"]},{"title":"pytorch的基本数据tensor","url":"/2022/09/21/pytorch%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE/","content":"<h1 id=\"pytorch的基本数据tensor\"><a href=\"#pytorch的基本数据tensor\" class=\"headerlink\" title=\"pytorch的基本数据tensor\"></a>pytorch的基本数据tensor</h1><p>Tensor，即张量，是PyTorch中的基本操作对象，可以看做是包含单一数据类型元素的多维矩阵。从使用角度来看，Tensor与NumPy的ndarrays非常类似，相互之间也可以自由转换，只不过Tensor还支持GPU的加速。</p>\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h80j83i5zrj314s0eddk9.jpg\" alt=\"85d160a859334f14bebdcc8c21eff18e  \" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h80j8tbe1vj30rn0kqgn9.jpg\" alt=\"9e2b11f3791a432eaf86169f5446bcf2 \" style=\"zoom:50%;\" />\n\n<h2 id=\"torch-FloatTensor\"><a href=\"#torch-FloatTensor\" class=\"headerlink\" title=\"torch.FloatTensor\"></a>torch.FloatTensor</h2><p>torch.FloatTensor用于生成数据类型为浮点型的Tensor，传递给torch.FloatTensor的参数可以是列表，也可以是一个维度值。</p>\n<pre><code class=\"python\">import torch\na = torch.FloatTensor(2,3)\nb = torch.FloatTensor([2,3,4,5])\na,b\n</code></pre>\n<p>得到的结果是：</p>\n<pre><code class=\"python\">(tensor([[1.0561e-38, 1.0102e-38, 9.6429e-39],\n         [8.4490e-39, 9.6429e-39, 9.1837e-39]]),\n tensor([2., 3., 4., 5.]))\n</code></pre>\n<h2 id=\"torch-IntTensor\"><a href=\"#torch-IntTensor\" class=\"headerlink\" title=\"torch.IntTensor\"></a>torch.IntTensor</h2><p>torch.IntTensor用于生成数据类型为整型的Tensor,传递给传递给torch.IntTensor的参数可以是列表，也可以是一个维度值。</p>\n<pre><code>import torch\na = torch.FloatTensor(2,3)\nb = torch.FloatTensor([2,3,4,5])\na,b\n</code></pre>\n<pre><code>import torch\na = torch.rand(2,3)\na \n</code></pre>\n<p>得到：</p>\n<pre><code>tensor([[0.5625, 0.5815, 0.8221],\n        [0.3589, 0.4180, 0.2158]])\n</code></pre>\n<h2 id=\"torch-randn\"><a href=\"#torch-randn\" class=\"headerlink\" title=\"torch.randn\"></a>torch.randn</h2><p>用于生成数据类型为浮点数且维度指定的随机Tensor，和在numpy中使用的numpy.randn生成的随机数的方法类似，随机生成的浮点数的取值满足均值为0，方差为1的正态分布。</p>\n<pre><code>import torch\na = torch.randn(2,3)\na \n</code></pre>\n<p>得到：</p>\n<pre><code>tensor([[-0.0067, -0.0707, -0.6682],\n        [ 0.8141,  1.1436,  0.5963]])\n</code></pre>\n<h2 id=\"torch-range\"><a href=\"#torch-range\" class=\"headerlink\" title=\"torch.range\"></a>torch.range</h2><p>torch.range用于生成数据类型为浮点型且起始范围和结束范围的Tensor，所以传递给torch.range的参数有三个，分别为起始值，结束值，步长，其中步长用于指定从起始值到结束值得每步的数据间隔。</p>\n<p>import torch<br>a &#x3D; torch.range(1,20,2)<br>a<br>1<br>2<br>3<br>得到：</p>\n<pre><code>tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19.])\n</code></pre>\n<h2 id=\"torch-zeros-x2F-ones-x2F-empty\"><a href=\"#torch-zeros-x2F-ones-x2F-empty\" class=\"headerlink\" title=\"torch.zeros&#x2F;ones&#x2F;empty\"></a>torch.zeros&#x2F;ones&#x2F;empty</h2><p>torch.zeros用于生成数据类型为浮点型且维度指定的Tensor，不过这个浮点型的Tensor中的元素值全部为0。</p>\n<p>torch.ones生成全1的数组。</p>\n<p>torch.empty创建一个未被初始化数值的tensor,tensor的大小是由size确定,size: 定义tensor的shape ，这里可以是一个list 也可以是一个tuple</p>\n<pre><code>import torch\na = torch.zeros(2,3)\na\n</code></pre>\n<p>得到：</p>\n<pre><code>tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n</code></pre>\n","categories":["deep learning"],"tags":["Pytorch"]},{"title":"如何重装anaconda","url":"/2022/10/01/%E5%A6%82%E4%BD%95%E9%87%8D%E8%A3%85anaconda/","content":"<h1 id=\"如何重装anaconda\"><a href=\"#如何重装anaconda\" class=\"headerlink\" title=\"如何重装anaconda\"></a>如何重装anaconda</h1><span id=\"more\"></span>\n<h2 id=\"一-卸载anaconda\"><a href=\"#一-卸载anaconda\" class=\"headerlink\" title=\"一.卸载anaconda\"></a>一.卸载anaconda</h2><p>因为之前下载过anaconda，所以各种配置都很乱，安装其他包问题不断，我决定重新安装一个anaconda，首先不要直接卸载anaconda，先运行如下命令</p>\n<pre><code>conda install anaconda-clean\nanaconda-clean--yes //会帮你备份一个配置文件，并删除之前的配置文件\n</code></pre>\n<p>在之后运行软件的卸载程序Uninstall-Anaconda3.exe就行了，在这之后就可以安装新的anaconda</p>\n<h2 id=\"二-安装anacoda\"><a href=\"#二-安装anacoda\" class=\"headerlink\" title=\"二.安装anacoda\"></a>二.安装anacoda</h2><p><strong>下载国内的清华园镜像，否则会很慢<a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/?C=M&O=D\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/?C=M&amp;O=D</a></strong></p>\n<p>然后正常安装，注意不要让他自动配置环境</p>\n<p>装完之后自己配环境</p>\n<pre><code>E:\\Anaconda（Python需要） \nE:\\Anaconda\\Scripts（conda自带脚本） \nE:\\Anaconda\\Library\\mingw-w64\\bin（使用C with python的时候） \nE:\\Anaconda\\Library\\bin（jupyter notebook动态库）\n</code></pre>\n<p>装完之后检测是否安装完成</p>\n<pre><code>conda info\n</code></pre>\n<p>找到.condarc文件，用记事本打开配置换源</p>\n<pre><code>channels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\nenvs_dirs:\n    ...       //根据你想要安装虚拟环境的路径来配\npkgs_dirs:\n    ...\t\t\t\t//根据你想要安装package cache的路径来配置\n</code></pre>\n","categories":["deep learning"],"tags":["Anaconda"]}]